{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入常用库\n",
    "import sys \n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sklearn \n",
    "import scipy\n",
    "import numpy as np\n",
    "import radiomics  #这个库专门用来提取特征\n",
    "from  radiomics import featureextractor\n",
    "import SimpleITK as sitk  #读取nii文件\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LassoCV#导入Lasso工具包LassoCV\n",
    "from sklearn.preprocessing import StandardScaler#标准化工具包StandardScaler\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取normal.csv和unnormal.csv ，因为是分类任务，新增标签1是unnormal，0标签是normal\n",
    "#还有各从normal.csv 和unnormal.csv随机抽取20%作为测试集\n",
    "\n",
    "def split_df(df, ratio):\n",
    "    #用来分割数据集，保留一定比例的数据集当做最终的测试集\n",
    "    cut_idx = int(round(0.1 * df.shape[0]))\n",
    "    data_test, data_train = df.iloc[:cut_idx], df.iloc[cut_idx:]\n",
    "    return (data_train, data_test)\n",
    "\n",
    "test_ratio = 0.2\n",
    "random_state = 2021 #固定随机种子\n",
    "normal_data = pd.read_excel(r'Path\\to\\normal.xlsx')\n",
    "unnormal_data = pd.read_excel(r'Path\\to\\unnormal.xlsx')\n",
    "\n",
    "# normal_data.insert(0,'label', 1) #插入标签\n",
    "# unnormal_data.insert(0,'label', 0) #插入标签\n",
    "\n",
    "normal_data = normal_data.sample(frac=1.0, random_state=random_state)  # 全部打乱\n",
    "unnormal_data = unnormal_data.sample(frac=1.0, random_state=random_state)  # 全部打乱\n",
    "\n",
    "#因为有些特征是字符串，直接删掉\n",
    "cols=[x for i,x in enumerate(normal_data.columns) if type(normal_data.iat[1,i]) == str]\n",
    "normal_data=normal_data.drop(cols,axis=1)\n",
    "cols=[x for i,x in enumerate(unnormal_data.columns) if type(unnormal_data.iat[1,i]) == str]\n",
    "unnormal_data=unnormal_data.drop(cols,axis=1)\n",
    "\n",
    "normal_data_train, normal_data_test = split_df(normal_data,test_ratio) #返回train 和test数据集\n",
    "unnormal_data_train, unnormal_data_test = split_df(unnormal_data,test_ratio) #返回train 和test数据集\n",
    "\n",
    "#保存测试集为cvs 后面最终验证使用\n",
    "normal_data_test.to_csv('normal_test.csv',index=False)\n",
    "unnormal_data_test.to_csv('unnormal_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看总数据类别是否平衡\n",
    "fig, ax = plt.subplots()\n",
    "sns.set()\n",
    "total_data = pd.concat([normal_data, unnormal_data])\n",
    "ax = sns.countplot(x='label',hue='label',data=total_data)\n",
    "print(total_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把normal_data_train 和unnormal_data_train 并在一起并且打乱。\n",
    "#查看总体数据情况\n",
    "data = pd.concat([normal_data_train, unnormal_data_train])\n",
    "data = data.sample(frac=1.0,random_state=random_state)  # 全部打乱\n",
    "print(\"一共有{}行特征数据\".format(len(data)))\n",
    "print(\"一共有{}列不同特征\".format(data.shape[1]))\n",
    "#再把特征值数据和标签数据分开\n",
    "x = data[data.columns[1:]]\n",
    "y = data['label']\n",
    "#取X的5行看看数据\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过T检验进行特征筛选\n",
    "from scipy.stats import levene, ttest_ind\n",
    "counts = 0\n",
    "columns_index =[]\n",
    "for column_name in normal_data_train.columns[1:]:\n",
    "    if levene(normal_data_train[column_name], unnormal_data_train[column_name])[1] > 0.05:\n",
    "        if ttest_ind(normal_data_train[column_name],unnormal_data_train[column_name],equal_var=True)[1] < 0.05:\n",
    "            columns_index.append(column_name)\n",
    "    else:\n",
    "        if ttest_ind(normal_data_train[column_name],unnormal_data_train[column_name],equal_var=False)[1] < 0.05:\n",
    "            columns_index.append(column_name)\n",
    "\n",
    "print(\"筛选后剩下的特征数：{}个\".format(len(columns_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kydavra import MUSESelector,PointBiserialCorrSelector,LassoSelector,ChiSquaredSelector,PointBiserialCorrSelector\n",
    "\n",
    "#数据只保留从T检验筛选出的特征数据，重新组合成data\n",
    "if  not 'label' in columns_index:\n",
    "    columns_index = ['label'] + columns_index\n",
    "normal_train = normal_data_train[columns_index]  \n",
    "unnormal_train = unnormal_data_train[columns_index]  \n",
    "\n",
    "data = pd.concat([normal_train, unnormal_train])\n",
    "data = data.sample(frac=1.0,random_state=random_state)  # 全部打乱\n",
    "\n",
    "#缪斯选择器筛选特征\n",
    "#主要思想是在一个特征下，不同 类别的分布是有明显差异的，如果各个类别都是均匀分布，那这个特征就没有用。\n",
    "max_columns_num = 20  #这个值是人工定义值\n",
    "muse = MUSESelector (num_features=max_columns_num)\n",
    "columns_index = muse.select(data, 'label')\n",
    "\n",
    "print(\"筛选后剩下的特征数：{}个\".format(len(columns_index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据只保留从T检验筛选出的特征数据，重新组合成data\n",
    "if  not 'label' in columns_index:\n",
    "    columns_index = ['label'] + columns_index\n",
    "normal_train = normal_data_train[columns_index]  \n",
    "unnormal_train = unnormal_data_train[columns_index]  \n",
    "\n",
    "data = pd.concat([normal_train, unnormal_train])\n",
    "data = data.sample(frac=1.0,random_state=random_state)  # 全部打乱\n",
    "\n",
    "#再把特征值数据和标签数据分开\n",
    "x = data[data.columns[1:]]\n",
    "y = data['label']\n",
    "#先保存X的列名\n",
    "columnNames = x.columns\n",
    "\n",
    "lassoCV_x = x.astype(np.float32)#把x数据转换成np.float格式\n",
    "lassoCV_y = y\n",
    "\n",
    "standardscaler = StandardScaler()\n",
    "lassoCV_x = standardscaler.fit_transform(lassoCV_x)#对x进行均值-标准差归一化\n",
    "lassoCV_x = pd.DataFrame(lassoCV_x,columns=columnNames)#转 DataFrame 格式\n",
    "\n",
    "# 形成5为底的指数函数\n",
    "# 5**（-3） ~  5**（-2）\n",
    "alpha_range = np.logspace(-3,-2,50,base=5)\n",
    "#alpha_range在这个参数范围里挑出aplpha进行训练，cv是把数据集分5分，进行交叉验证，max_iter是训练1000轮\n",
    "lassoCV_model = LassoCV(alphas=alpha_range,cv=5,max_iter=1000)\n",
    "#进行训练\n",
    "lassoCV_model.fit(lassoCV_x,lassoCV_y)\n",
    "\n",
    "#打印训练找出来的入值\n",
    "print(lassoCV_model.alpha_)\n",
    "# 模型的系数和截距\n",
    "# print(\"Coefficient of the model:{}\".format(lassoCV_model.coef_) )\n",
    "# print(\"intercept of the model:{}\".format(lassoCV_model.intercept_))\n",
    "\n",
    "coef = pd.Series(lassoCV_model.coef_, index=columnNames)\n",
    "print(\"从原来{}个特征，筛选剩下{}个\".format(len(columnNames),sum(coef !=0)))\n",
    "print(\"分别是以下特征\")\n",
    "print(coef[coef !=0])\n",
    "index = coef[coef !=0].index\n",
    "lassoCV_x = lassoCV_x[index]\n",
    "# lassoCV_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制特征相关系数热力图\n",
    "import seaborn as sns\n",
    "f, ax= plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(lassoCV_x.corr(),annot=True,cmap='coolwarm',annot_kws={'size':10,'weight':'bold', },ax=ax)#绘制混淆矩阵\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45,va=\"top\",ha=\"right\")\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画一个特征系数的柱状图\n",
    "weight = coef[coef !=0].to_dict()\n",
    "#根据值大小排列一下\n",
    "weight = dict(sorted(weight.items(),key=lambda x:x[1],reverse=False))\n",
    "plt.figure(figsize=(8,6))#设置画布的尺寸\n",
    "plt.title('characters classification weight',fontsize=15)#标题，并设定字号大小\n",
    "plt.xlabel(u'weighted value',fontsize=14)#设置x轴，并设定字号大小\n",
    "plt.ylabel(u'feature')\n",
    "plt.barh(range(len(weight.values())), list(weight.values()),tick_label = list(weight.keys()),alpha=0.6, facecolor = 'blue', edgecolor = 'black', label='feature weight')\n",
    "plt.legend(loc=4)#图例展示位置，数字代表第几象限\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制误差棒图\n",
    "MSEs = lassoCV_model.mse_path_\n",
    "mse = list()\n",
    "std = list()\n",
    "for m in MSEs:\n",
    "    mse.append(np.mean(m))\n",
    "    std.append(np.std(m))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.errorbar(lassoCV_model.alphas_, mse, std,fmt='o:',ecolor='lightblue',\n",
    "\t\t\telinewidth=3,ms=5,mfc='wheat',mec='salmon',capsize=3)\n",
    "plt.axvline(lassoCV_model.alpha_, color='red', ls='--')\n",
    "plt.title('Errorbar')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个图显示随着lambda 的变化，系数的变化走势\n",
    "x = data[data.columns[1:]]\n",
    "y = data['label']\n",
    "#先保存X的列名\n",
    "columnNames = x.columns\n",
    "lassoCV_x = x.astype(np.float32)#把x数据转换成np.float格式\n",
    "lassoCV_y = y\n",
    "lassoCV_x = standardscaler.transform(lassoCV_x)#对x进行均值-标准差归一化\n",
    "lassoCV_x = pd.DataFrame(lassoCV_x,columns=columnNames)#转 DataFrame 格式\n",
    "coefs = lassoCV_model.path(lassoCV_x,lassoCV_y, alphas=alpha_range,max_iter=1000)[1].T\n",
    "plt.plot(lassoCV_model.alphas,coefs,'-')\n",
    "plt.axvline(lassoCV_model.alpha_, color='red', ls='--')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('coef')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #分割训练集和验证集\n",
    "from sklearn.ensemble import RandomForestClassifier #导入随机森林分类器\n",
    "import joblib #用来保存 sklearn 训练好的模型\n",
    "#把数据分成训练集和验证集，7：3比例\n",
    "index_ = coef[coef !=0].index\n",
    "rforest_x = x[index_]\n",
    "rforest_y = y\n",
    "standardscaler = StandardScaler()\n",
    "rforest_x = standardscaler.fit_transform(rforest_x)#对x进行均值-标准差归一化\n",
    "x_train,x_test, y_train, y_test = train_test_split(rforest_x,rforest_y,test_size=0.2)\n",
    "model_forest = RandomForestClassifier(n_estimators=30,random_state=random_state).fit(x_train,y_train)\n",
    "score = model_forest.score(x_test, y_test)\n",
    "print(\"在验证集上的准确率：{}\".format(score))\n",
    "#把随机森林的模型保存下来\n",
    "joblib.dump(model_forest, 'model/model_forest1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "normal_test = pd.read_csv(r'Path\\to\\normal_test.csv')\n",
    "unnormal_test = pd.read_csv(r'Path\\to\\unnormal_test.csv')\n",
    "#再把特征值数据和标签数据分开\n",
    "data_test = pd.concat([normal_test,unnormal_test],axis=0)\n",
    "\n",
    "x_test_data = data_test[data_test.columns[1:]]\n",
    "#只提取之前Lasso 筛选后的\n",
    "index = coef[coef !=0].index\n",
    "x_test_data = x_test_data[index]\n",
    "\n",
    "columnNames = x_test_data.columns\n",
    "x_test_data = x_test_data.astype(np.float32)\n",
    "\n",
    "x_test_data = standardscaler.transform(x_test_data) #均值-标准差归一化\n",
    "x_test_data = pd.DataFrame(x_test_data,columns=columnNames)\n",
    "y_test_data = data_test['label']\n",
    "\n",
    "print(\"测试集一共有{}行特征数据，{}列不同特征,包含normal:{}例，unnormal:{}例\".format(len(x_test_data),x_test_data.shape[1],len(normal_data_test),len(unnormal_data_test)))\n",
    "#加载保存后的模型，然后进行预测\n",
    "model_forest = joblib.load('model/model_forest1.model') #这是自己训练模型，记得替换自己的。\n",
    "score = model_forest.score(x_test_data, y_test_data)\n",
    "print(\"在测试集上的准确率：{}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#绘制混淆矩阵图方法1\n",
    "import seaborn as sns\n",
    "\n",
    "predict_label = model_forest.predict(x_test_data) #预测的标签\n",
    "label = y_test_data.to_list()  #真实标签\n",
    "confusion = confusion_matrix(label, predict_label)#计算混淆矩阵\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(confusion,cmap='Blues_r',annot=True,annot_kws={'size':20,'weight':'bold', })#绘制混淆矩阵\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "#绘制混淆图方法2,一行代码\n",
    "# plot_confusion_matrix(model_forest, x_test_data, y_test_data,values_format='d',cmap='GnBu_r')\n",
    "\n",
    "\n",
    "print(\"混淆矩阵为：\\n{}\".format(confusion))\n",
    "print(\"\\n计算各项指标：\")\n",
    "print(classification_report(label, predict_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制ROC曲线,方法1\n",
    "import joblib\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,auc\n",
    "kind = {'normal':0,\"unnormal\":1}\n",
    "model_forest = joblib.load('model/model_forest1.model')#这是自己训练模型，记得替换自己的\n",
    "label = y_test_data.to_list()  #真实标签\n",
    "y_predict = model_forest.predict_proba(x_test_data)#得到标签0和1对应的概率\n",
    "fpr , tpr ,threshold = roc_curve(label, y_predict[:,kind['unnormal']], pos_label=kind['unnormal'])\n",
    "roc_auc = auc(fpr,tpr) #计算auc的\n",
    "fpr1 , tpr1 ,threshold = roc_curve(label, y_predict[:,kind['normal']], pos_label=kind['normal'])\n",
    "roc_auc1 = auc(fpr1,tpr1) #计算auc的\n",
    "plt.plot(fpr, tpr,marker='o', markersize=5,label='unnormal')\n",
    "plt.plot(fpr1, tpr1,marker='*', markersize=5,label='normal')\n",
    "plt.title(\"unnormal AUC:{:.2f}, normal AUC:{:.2f}\".format(roc_auc,roc_auc1))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘制ROC方法2,两行代码\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "ax1 = RocCurveDisplay.from_estimator(model_forest, x_test_data, y_test_data, name='unnormal',pos_label=1)\n",
    "RocCurveDisplay.from_estimator(model_forest, x_test_data, y_test_data, ax=ax1.ax_,name='normal',pos_label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "# 绘制PR曲线\n",
    "PrecisionRecallDisplay.from_predictions(label, (y_predict[:,1] > 0.5).astype(int),name=\"PR\",pos_label=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict[:,0])\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
